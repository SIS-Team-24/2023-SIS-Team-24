import React from "react";
import ExpandMoreIcon from "@material-ui/icons/ExpandMore";
import Accordion from "@material-ui/core/Accordion";
import AccordionDetails from "@material-ui/core/AccordionDetails";
import Typography from "@material-ui/core/Typography";
import AccordionSummary from "@material-ui/core/AccordionSummary";
import NavigationBar from "./NavigationBar";

function LearnMore() {
  const questions = [
    {
      q: "What is Text Insights?",
      a: "Text Insights is an online text summariser application that provides users with concise summaries of longer text documents. Additionally, it offers sentiment analysis to determine whether the text is positive, negative, or neutral, along with a percentage score.",
    },
    {
      q: "What is NLP?",
      a: "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language, facilitating interaction between machines and humans.",
    },
    {
      q: "How does Text Insights summarise text?",
      a: "Text Insights uses the powerful BERT (Bidirectional Encoder Representations from Transformers) model for text summarisation. BERT's advanced natural language understanding capabilities help identify key sentences and phrases, allowing it to create coherent and accurate summaries.",
    },
    {
      q: "What is sentiment analysis, and why is it important?",
      a: "Sentiment analysis is the process of determining the emotional tone of a piece of text, whether it's positive, negative, or neutral. It's important because it helps users quickly gauge the overall sentiment of a document, which can be useful for making informed decisions or understanding public opinion.",
    },
    {
      q: "How accurate is Text Insights' sentiment analysis using BERT?",
      a: "Text Insights utilises BERT-based sentiment analysis models, known for their high accuracy in understanding the emotional tone of text. While no sentiment analysis tool is perfect, BERT enhances accuracy by capturing context and nuances effectively.",
    },
    {
      q: "Can Text Insights summarise any type of text?",
      a: "Text Insights can summarise a wide range of text types, including articles, reports, essays, news articles, and more. It works best with well-structured text, but it can handle various formats.",
    },
    {
      q: "What is the maximum length of the summary generated by Text Insights?",
      a: "The maximum summary length generated by Text Insights is set at 400 words. This ensures that the summary remains concise while capturing the most important information from the original text.",
    },
  ];

  const LMSquestions = [
    {
      q: " What dataset was Text Insights trained on?",
      a: "BERT, an acronym for Bidirectional Encoder Representations from Transformers, stands as a Machine Learning (ML) model designed for the purpose of natural language processing. Developed in 2018 by experts at Google AI Language, BERT serves as a versatile solution to more than 11 common language tasks, including tasks like determining sentiment in text and identifying named entities. Traditionally, enabling computers to truly 'comprehend' language has posed challenges. While computers can gather, store, and read textual information, they lack fundamental understanding of language nuances. This led to the emergence of Natural Language Processing (NLP): an artificial intelligence field that strives to empower computers to read, dissect, interpret, and extract meaning from written and spoken language. This discipline combines elements of linguistics, statistics, and Machine Learning to aid computers in achieving a level of 'comprehension' of human language.",
      link: "https://d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html",
    },
    {
      q: "How does BERT work?",
      a: "BERT's sustained success can be attributed to a colossal dataset of 3.3 Billion words. BERT underwent specific training using Wikipedia (around 2.5 billion words) and Google's BooksCorpus (approximately 800 million words). These extensive repositories of information significantly enriched BERT's profound understanding of not only the English language but also our global reality! ðŸš€ Training on such an extensive dataset demands considerable time investment. BERT's training became feasible owing to the innovative Transformer architecture, further accelerated by the utilisation of TPUs (Tensor Processing Units)â€”specialised circuits developed by Google explicitly for handling large-scale ML models. BERT's training, executed with 64 TPUs, was accomplished within a span of 4 days. It's worth noting that the need for more compact BERT models is growing, driven by the intention to incorporate BERT in smaller computational contexts like smartphones and personal computers. In March 2020, a collection of 23 scaled-down BERT models was introduced. DistilBERT, for instance, presents a lighter iteration of BERT that operates with a 60% speed boost while retaining over 95% of BERT's performance level.",
      link: "https://huggingface.co/blog/bert-101#2-how-does-bert-work",
    },
  ];

  return (
    <div>
      <NavigationBar />

      <hr className="h-px mt-2 border-0 bg-gray-300"></hr>
      <div className="mt-20 font-extrabold">
        <span className="mb-10 font-bold text-3xl flex flex-col items-center justify-center mt-10">
          Learn More...
        </span>
        <span className="mb-10 font-bold text-2xl flex flex-col items-center justify-center mt-10">
          Frequently Asked Questions
        </span>
        <div className="font-normal flex flex-col items-center justify-center ">
          {questions.map((question, index) => (
            <Accordion
              key={index}
              className="items-center content-center w-2/5"
            >
              <AccordionSummary
                expandIcon={<ExpandMoreIcon />}
                aria-controls={`panella-content-${index}`}
              >
                <Typography>
                  <h2 className="faq-question font-semibold">{question.q}</h2>
                </Typography>
              </AccordionSummary>
              <AccordionDetails>
                <Typography className="faq-answer font-normal">
                  <h2>{question.a}</h2>
                </Typography>
              </AccordionDetails>
            </Accordion>
          ))}
        </div>

        <span className="mb-10 font-bold text-2xl flex flex-col items-center justify-center mt-10">
          Machine Learning (NLP) Material Summary
        </span>

        <div className="mt-50" />
        <div className="font-normal flex flex-col items-center justify-center ">
          {LMSquestions.map((question, index) => (
            <Accordion
              key={index}
              className="items-center content-center w-2/5"
            >
              <AccordionSummary
                expandIcon={<ExpandMoreIcon />}
                aria-controls={`panella-content-${index}`}
              >
                <Typography>
                  <h2 className="font-semibold">{question.q}</h2>
                </Typography>
              </AccordionSummary>
              <AccordionDetails>
                <Typography className="font-normal">
                  <h2 id={index.toString()}>{question.a}</h2>
                  <br />
                  <h2>
                    If you want to learn more about BERT, here is a link:{" "}
                  </h2>
                  <a href={question.link} className="mt-5 ml-30 text-blue-600">
                    {question.link}
                  </a>
                </Typography>
              </AccordionDetails>
            </Accordion>
          ))}
        </div>
      </div>

      <div className="mt-20" />
    </div>
  );
}

export default LearnMore;
